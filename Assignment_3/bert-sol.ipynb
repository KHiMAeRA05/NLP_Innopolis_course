{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8246465,"sourceType":"datasetVersion","datasetId":4892512}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialize paths to datasets","metadata":{}},{"cell_type":"code","source":"train_path_dataset = '/kaggle/input/github/Assignment_3/train.jsonl'\ntest_path_dataset = '/kaggle/input/github/Assignment_3/test.jsonl'\nners_path = '/kaggle/input/github/Assignment_3/ners.txt'","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:23:36.641677Z","iopub.execute_input":"2024-04-28T10:23:36.642045Z","iopub.status.idle":"2024-04-28T10:23:36.656241Z","shell.execute_reply.started":"2024-04-28T10:23:36.642014Z","shell.execute_reply":"2024-04-28T10:23:36.654862Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Install and import libraries ","metadata":{}},{"cell_type":"code","source":"!pip install -q peft transformers datasets evaluate seqeval","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:23:44.222034Z","iopub.execute_input":"2024-04-28T10:23:44.222453Z","iopub.status.idle":"2024-04-28T10:24:04.363425Z","shell.execute_reply.started":"2024-04-28T10:23:44.222419Z","shell.execute_reply":"2024-04-28T10:24:04.362265Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:24:04.365627Z","iopub.execute_input":"2024-04-28T10:24:04.365946Z","iopub.status.idle":"2024-04-28T10:24:04.370306Z","shell.execute_reply.started":"2024-04-28T10:24:04.365919Z","shell.execute_reply":"2024-04-28T10:24:04.369425Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import json\nimport torch\nfrom datasets import Dataset\n\nfrom nltk.data import load\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T10:24:26.618219Z","iopub.execute_input":"2024-04-28T10:24:26.619029Z","iopub.status.idle":"2024-04-28T10:24:39.221015Z","shell.execute_reply.started":"2024-04-28T10:24:26.619000Z","shell.execute_reply":"2024-04-28T10:24:39.219927Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Load all entities and give them ids\n\ndef load_entities():\n    tag_list = []\n    \n    with open(ners_path, \"r\", encoding='UTF-8') as ners_file:\n\n        tags = [t.strip() for t in ners_file.read().split('\\n')]\n        tags = tags[:-1]\n        \n        tag_to_id = {}\n        id_to_tag = {}\n        tag_list.append('O')\n        for idx, tag in enumerate(tags):\n            tag_to_id['B-' + tag] = idx * 4 + 1\n            tag_to_id['I-' + tag] = idx * 4 + 2\n            tag_to_id['E-' + tag] = idx * 4 + 3\n            tag_to_id['S-' + tag] = idx * 4 + 4\n            \n            id_to_tag[idx * 4 + 1] = 'B-' + tag\n            id_to_tag[idx * 4 + 2] = 'I-' + tag\n            id_to_tag[idx * 4 + 3] = 'E-' + tag\n            id_to_tag[idx * 4 + 4] = 'S-' + tag\n            \n            tag_list.append('B-' + tag)\n            tag_list.append('I-' + tag)\n            tag_list.append('E-' + tag)\n            tag_list.append('S-' + tag)\n        tag_to_id['O'] = 0\n        id_to_tag[0] = 'O'\n\n        tag_to_id\n    \n    return tag_list, tag_to_id, id_to_tag\n\ntag_list, tag_to_id, id_to_tag = load_entities()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:24:39.222969Z","iopub.execute_input":"2024-04-28T10:24:39.223630Z","iopub.status.idle":"2024-04-28T10:24:39.246879Z","shell.execute_reply.started":"2024-04-28T10:24:39.223592Z","shell.execute_reply":"2024-04-28T10:24:39.246005Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\nclass IOBESFlatRuNNEDataset:\n    def __init__(self, tokenizer, json_file_path):\n        \"\"\"\n        Initialize the dataset with a tokenizer and the path to the JSONL file.\n        \n        Args:\n        - tokenizer: A tokenizer object (e.g., from Hugging Face's transformers library).\n        - json_file_path: Path to the JSONL file containing the data.\n        \"\"\"\n        self.tokenizer = tokenizer\n        self.json_file_path = json_file_path\n\n    def _filter_flat_ners(self, entities):\n        \"\"\"\n        Filter out nested named entities from the list of entities.\n        \n        Args:\n        - entities: List of named entity tuples (start, end, label).\n        \n        Returns:\n        - List of flat named entity tuples.\n        \"\"\"\n        flat_entities = []\n\n        for entity in entities:\n            start, end, _ = entity\n            if not any(start >= e[0] and end <= e[1] for e in entities if e != entity):\n                flat_entities.append(entity)\n\n        return flat_entities\n\n    def _tokenize_sentences(self, flat_data):\n        \"\"\"\n        Tokenize the sentences in the dataset and prepare them for training.\n        \n        Args:\n        - flat_data: DataFrame containing the flat entities and sentences.\n        \n        Returns:\n        - Updated DataFrame with tokenized data.\n        \"\"\"\n        token_indices = []\n        tokens = []\n        offsets = []\n        attention_masks = []\n\n        for _, row in tqdm(flat_data.iterrows(), desc=\"Tokenizing sentences\"):\n            context = row[\"sentences\"]\n            encoding = self.tokenizer.encode_plus(context, truncation=True, add_special_tokens=False, return_offsets_mapping=True)\n            offsets.append(encoding.offset_mapping)\n            tokens.append(encoding.input_ids)\n            attention_masks.append(encoding.attention_mask)\n\n            offset_to_token_start = {}\n            offset_to_token_end = {}\n            for token_idx, (start, end) in enumerate(offsets[-1]):\n                if start == end == 0:\n                    continue\n                offset_to_token_start[start] = token_idx\n                offset_to_token_end[end - 1] = token_idx\n\n            valid_ners = []\n            for start, end, label in row[\"flat_ners\"]:\n                try:\n                    new_start = offset_to_token_start[start]\n                    new_end = offset_to_token_end[end]\n                except KeyError:\n                    continue\n                valid_ners.append([new_start, new_end, label])\n\n            token_indices.append(valid_ners)\n\n        flat_data['token_indices'] = token_indices\n        flat_data['input_ids'] = tokens\n        flat_data['offset_mapping'] = offsets\n        flat_data['attention_mask'] = attention_masks\n\n        return flat_data\n\n    def _convert_to_iobes_labels(self, flat_data):\n        \"\"\"\n        Convert the token indices to IOBES format labels.\n        \n        Args:\n        - flat_data: DataFrame containing token indices.\n        \n        Returns:\n        - Updated DataFrame with IOBES format labels.\n        \"\"\"\n        labeled_data = []\n        for _, row in tqdm(flat_data.iterrows(), desc=\"Converting to IOBES labels\"):\n            labels = []\n\n            for e in row[\"token_indices\"]:\n                labels.append((e[0], e[1], e[2]))\n\n            label_seq = [\"O\"] * len(row['input_ids'])\n\n            for start, end, tag in labels:\n                if start == end:\n                    label_seq[start] = 'S-' + tag\n                else:\n                    label_seq[start] = 'B-' + tag\n                    label_seq[end] = 'E-' + tag\n                    for i in range(start + 1, end):\n                        label_seq[i] = 'I-' + tag\n\n            labeled_data.append([tag_to_id.get(label) for label in label_seq])\n\n        flat_data['labels'] = labeled_data\n\n        return flat_data\n    \n    def _show_entity_changes(self, json_data):\n        \"\"\"\n        Calculate the percentage change in the number of named entities after preprocessing.\n        \n        Args:\n        - entities: List of original named entities.\n        - flat_entities: List of flat named entities after preprocessing.\n        \n        Prints:\n        - Mean percentage change per row.\n        \"\"\"\n        entities = json_data['ners'].tolist()\n        flat_entities = json_data['flat_ners'].tolist()\n        \n        changes = [(len(entities[i]) - len(flat_entities[i])) / len(entities[i]) * 100 for i in range(len(entities))]\n        \n        ner_changes = sum(changes) / len(changes) if len(changes) > 0 else 0\n        \n        print(f\"Mean percentage change in number of named entities: {ner_changes:.2f}%\")\n        \n\n    def get_dataset(self):\n        \"\"\"\n        Load and preprocess the dataset.\n        \n        Returns:\n        - DataFrame containing the tokenized dataset with IOBES format labels.\n        \"\"\"\n        print(\"Loading data...\")\n        json_data = pd.read_json(self.json_file_path, lines=True)\n        json_data = json_data[json_data.columns[::-1]]\n\n        print(\"Getting flat entities...\")\n        flat_ners = [self._filter_flat_ners(row[\"ners\"]) for _, row in tqdm(json_data.iterrows(), desc=\"Filtering flat entities\")]\n        json_data['flat_ners'] = flat_ners\n\n        json_data = self._tokenize_sentences(json_data)\n        json_data = self._convert_to_iobes_labels(json_data)\n        \n        for _, row in tqdm(json_data.iterrows(), desc=\"Checking for errors\"):\n            assert len(row['input_ids']) == len(row['attention_mask']) \n            assert len(row['attention_mask']) == len(row['offset_mapping'])\n            assert len(row['offset_mapping']) == len(row['labels'])\n        \n        self._show_entity_changes(json_data)\n        \n        return json_data[['input_ids', 'attention_mask', 'offset_mapping', 'labels']]","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:24:39.248109Z","iopub.execute_input":"2024-04-28T10:24:39.248378Z","iopub.status.idle":"2024-04-28T10:24:39.273738Z","shell.execute_reply.started":"2024-04-28T10:24:39.248355Z","shell.execute_reply":"2024-04-28T10:24:39.272888Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess data","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoModelForTokenClassification,\n    AutoTokenizer,\n    DataCollatorForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    BertForTokenClassification\n)\n\nmodel_checkpoint = \"bert-base-multilingual-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:24:39.275665Z","iopub.execute_input":"2024-04-28T10:24:39.275965Z","iopub.status.idle":"2024-04-28T10:25:00.041552Z","shell.execute_reply.started":"2024-04-28T10:24:39.275941Z","shell.execute_reply":"2024-04-28T10:25:00.040750Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-04-28 10:24:45.954978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 10:24:45.955132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 10:24:46.222500: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1aa70ca1ba4fb483474677ade8a846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c858c1d9da134437b34759b910362b1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6f045a80dc443fb9840f9e1e08cc87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003c4ce127ef49498846201efefabd1d"}},"metadata":{}}]},{"cell_type":"code","source":"df = IOBESFlatRuNNEDataset(tokenizer, train_path_dataset).get_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:00.042645Z","iopub.execute_input":"2024-04-28T10:25:00.043176Z","iopub.status.idle":"2024-04-28T10:25:02.207366Z","shell.execute_reply.started":"2024-04-28T10:25:00.043151Z","shell.execute_reply":"2024-04-28T10:25:02.206405Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loading data...\nGetting flat entities...\n","output_type":"stream"},{"name":"stderr","text":"Filtering flat entities: 519it [00:00, 1065.35it/s]\nTokenizing sentences: 519it [00:01, 389.69it/s]\nConverting to IOBES labels: 519it [00:00, 5388.33it/s]\nChecking for errors: 519it [00:00, 11965.94it/s]","output_type":"stream"},{"name":"stdout","text":"Mean percentage change in number of named entities: 20.93%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:02.208584Z","iopub.execute_input":"2024-04-28T10:25:02.208863Z","iopub.status.idle":"2024-04-28T10:25:02.263802Z","shell.execute_reply.started":"2024-04-28T10:25:02.208839Z","shell.execute_reply":"2024-04-28T10:25:02.262879Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [95931, 34936, 543, 48645, 16882, 33933, 11977...   \n\n                                      attention_mask  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                      offset_mapping  \\\n0  [(0, 2), (2, 6), (7, 8), (8, 11), (11, 15), (1...   \n\n                                              labels  \n0  [9, 11, 33, 34, 35, 41, 42, 42, 42, 42, 42, 42...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>offset_mapping</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[95931, 34936, 543, 48645, 16882, 33933, 11977...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[(0, 2), (2, 6), (7, 8), (8, 11), (11, 15), (1...</td>\n      <td>[9, 11, 33, 34, 35, 41, 42, 42, 42, 42, 42, 42...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Get ready for training","metadata":{}},{"cell_type":"code","source":"from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\nimport evaluate\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:02.264902Z","iopub.execute_input":"2024-04-28T10:25:02.265190Z","iopub.status.idle":"2024-04-28T10:25:02.399061Z","shell.execute_reply.started":"2024-04-28T10:25:02.265165Z","shell.execute_reply":"2024-04-28T10:25:02.398304Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)\n\nsplitted_dataset  = dataset.train_test_split(test_size=0.2)\nsplitted_dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:02.400202Z","iopub.execute_input":"2024-04-28T10:25:02.400553Z","iopub.status.idle":"2024-04-28T10:25:02.718838Z","shell.execute_reply.started":"2024-04-28T10:25:02.400526Z","shell.execute_reply":"2024-04-28T10:25:02.717810Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'offset_mapping', 'labels'],\n    num_rows: 415\n})"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:02.720296Z","iopub.execute_input":"2024-04-28T10:25:02.720685Z","iopub.status.idle":"2024-04-28T10:25:02.727447Z","shell.execute_reply.started":"2024-04-28T10:25:02.720652Z","shell.execute_reply":"2024-04-28T10:25:02.726446Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(model_checkpoint, id2label=id_to_tag, label2id=tag_to_id,\n                                                   num_labels = 29 * 4 + 1, return_dict = False)\nseqeval = evaluate.load(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:02.730270Z","iopub.execute_input":"2024-04-28T10:25:02.730668Z","iopub.status.idle":"2024-04-28T10:25:07.641906Z","shell.execute_reply.started":"2024-04-28T10:25:02.730642Z","shell.execute_reply":"2024-04-28T10:25:07.641079Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ff40afba9a47139aa8a35ecc0c3729"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99296ecb8b7945799179601f45245e91"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(p, label_list = tag_list):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    \n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label)]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label)]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:07.643043Z","iopub.execute_input":"2024-04-28T10:25:07.643345Z","iopub.status.idle":"2024-04-28T10:25:07.651668Z","shell.execute_reply.started":"2024-04-28T10:25:07.643318Z","shell.execute_reply":"2024-04-28T10:25:07.650743Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"peft_config = LoraConfig(\n    task_type=TaskType.TOKEN_CLS, inference_mode=False, \n    r=16, lora_alpha=32, lora_dropout=0.1, bias=\"all\",\n    target_modules=['guery', 'key', 'value', 'dense']\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:07.653183Z","iopub.execute_input":"2024-04-28T10:25:07.653507Z","iopub.status.idle":"2024-04-28T10:25:07.676710Z","shell.execute_reply.started":"2024-04-28T10:25:07.653480Z","shell.execute_reply":"2024-04-28T10:25:07.675525Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:25:07.677996Z","iopub.execute_input":"2024-04-28T10:25:07.678285Z","iopub.status.idle":"2024-04-28T10:25:07.926343Z","shell.execute_reply.started":"2024-04-28T10:25:07.678259Z","shell.execute_reply":"2024-04-28T10:25:07.925314Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"trainable params: 2,551,413 || all params: 179,802,090 || trainable%: 1.4190118702179713\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = \"trained_weigths\"\n\nlr = 1e-3\nbatch_size = 16\nnum_epochs = 10\n\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    report_to=None,\n    metric_for_best_model='eval_f1',\n    log_level='critical',\n    seed=12345\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:30:15.631314Z","iopub.execute_input":"2024-04-28T10:30:15.631733Z","iopub.status.idle":"2024-04-28T10:30:15.667508Z","shell.execute_reply.started":"2024-04-28T10:30:15.631700Z","shell.execute_reply":"2024-04-28T10:30:15.666594Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport os\n\nwandb.init(mode=\"disabled\")\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ntorch.cuda.empty_cache() ","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:30:16.009804Z","iopub.execute_input":"2024-04-28T10:30:16.010184Z","iopub.status.idle":"2024-04-28T10:30:16.436826Z","shell.execute_reply.started":"2024-04-28T10:30:16.010153Z","shell.execute_reply":"2024-04-28T10:30:16.435977Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=splitted_dataset[\"train\"],\n    eval_dataset=splitted_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:34:52.012026Z","iopub.execute_input":"2024-04-28T10:34:52.013090Z","iopub.status.idle":"2024-04-28T10:39:17.528486Z","shell.execute_reply.started":"2024-04-28T10:34:52.013056Z","shell.execute_reply":"2024-04-28T10:39:17.527562Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'eval_loss': 0.4461127817630768, 'eval_precision': 0.4587609274040289, 'eval_recall': 0.24058202112816424, 'eval_f1': 0.31563807531380755, 'eval_accuracy': 0.7041954627403846, 'eval_runtime': 4.6368, 'eval_samples_per_second': 22.429, 'eval_steps_per_second': 0.863, 'epoch': 1.0}\n{'eval_loss': 0.37188318371772766, 'eval_precision': 0.5243726564753389, 'eval_recall': 0.24157863264899343, 'eval_f1': 0.33077098021378215, 'eval_accuracy': 0.7232008713942307, 'eval_runtime': 4.4974, 'eval_samples_per_second': 23.124, 'eval_steps_per_second': 0.889, 'epoch': 2.0}\n{'eval_loss': 0.3952161371707916, 'eval_precision': 0.5141061452513966, 'eval_recall': 0.24456846721148096, 'eval_f1': 0.3314573859799198, 'eval_accuracy': 0.7223745492788461, 'eval_runtime': 4.4837, 'eval_samples_per_second': 23.195, 'eval_steps_per_second': 0.892, 'epoch': 3.0}\n{'eval_loss': 0.4153476059436798, 'eval_precision': 0.5188507358093903, 'eval_recall': 0.24596372334064182, 'eval_f1': 0.3337239700712161, 'eval_accuracy': 0.7206843449519231, 'eval_runtime': 4.5255, 'eval_samples_per_second': 22.981, 'eval_steps_per_second': 0.884, 'epoch': 4.0}\n{'eval_loss': 0.4393611252307892, 'eval_precision': 0.4788913127165405, 'eval_recall': 0.24795694638230018, 'eval_f1': 0.3267378742777097, 'eval_accuracy': 0.7163649338942307, 'eval_runtime': 4.509, 'eval_samples_per_second': 23.065, 'eval_steps_per_second': 0.887, 'epoch': 5.0}\n{'eval_loss': 0.42277291417121887, 'eval_precision': 0.5006010418057967, 'eval_recall': 0.24901999867118463, 'eval_f1': 0.33259384151211285, 'eval_accuracy': 0.7196138822115384, 'eval_runtime': 4.4665, 'eval_samples_per_second': 23.285, 'eval_steps_per_second': 0.896, 'epoch': 6.0}\n{'eval_loss': 0.42459550499916077, 'eval_precision': 0.5098119939618498, 'eval_recall': 0.24682745332536044, 'eval_f1': 0.3326170650908766, 'eval_accuracy': 0.7235013521634616, 'eval_runtime': 4.4807, 'eval_samples_per_second': 23.211, 'eval_steps_per_second': 0.893, 'epoch': 7.0}\n{'eval_loss': 0.4322647750377655, 'eval_precision': 0.5041846652267818, 'eval_recall': 0.248156268686466, 'eval_f1': 0.3326060821942206, 'eval_accuracy': 0.7214731069711539, 'eval_runtime': 4.5088, 'eval_samples_per_second': 23.066, 'eval_steps_per_second': 0.887, 'epoch': 8.0}\n{'eval_loss': 0.4343850910663605, 'eval_precision': 0.5020145044319098, 'eval_recall': 0.24835559099063184, 'eval_f1': 0.33231097479663957, 'eval_accuracy': 0.7224872295673077, 'eval_runtime': 4.783, 'eval_samples_per_second': 21.744, 'eval_steps_per_second': 0.836, 'epoch': 9.0}\n{'eval_loss': 0.43467843532562256, 'eval_precision': 0.503438047728192, 'eval_recall': 0.24808982791841075, 'eval_f1': 0.332383834787253, 'eval_accuracy': 0.7225060096153846, 'eval_runtime': 4.5853, 'eval_samples_per_second': 22.681, 'eval_steps_per_second': 0.872, 'epoch': 10.0}\n{'train_runtime': 264.7249, 'train_samples_per_second': 15.677, 'train_steps_per_second': 0.491, 'train_loss': 0.1657801994910607, 'epoch': 10.0}\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=130, training_loss=0.1657801994910607, metrics={'train_runtime': 264.7249, 'train_samples_per_second': 15.677, 'train_steps_per_second': 0.491, 'train_loss': 0.1657801994910607, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"# Read JSONL file\njson_data = pd.read_json(test_path_dataset, lines=True)\njson_data = json_data[json_data.columns[::-1]]\ntest_data = json_data.rename(columns={\"senences\": \"sentences\"})\n\n# Display the DataFrame\ntest_data.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:39:33.753889Z","iopub.execute_input":"2024-04-28T10:39:33.754260Z","iopub.status.idle":"2024-04-28T10:39:33.794331Z","shell.execute_reply.started":"2024-04-28T10:39:33.754230Z","shell.execute_reply":"2024-04-28T10:39:33.793453Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"    id                                          sentences\n0  584  Владелец «Бирмингема» получил шесть лет тюрьмы...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>584</td>\n      <td>Владелец «Бирмингема» получил шесть лет тюрьмы...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def normalize_preds(preds):\n    norm_preds = []\n    start_e = 0\n    end_e = 0\n    for entity, word, start, end in preds:\n        if entity[0] == 'S':\n            norm_preds.append([start, end-1, entity[2:]])\n        if entity[0] == 'B':\n            start_e = start\n        if entity[0] == 'E':\n            end_e = end-1\n            norm_preds.append([start_e, end_e, entity[2:]])\n            \n    return norm_preds","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:39:36.222271Z","iopub.execute_input":"2024-04-28T10:39:36.222667Z","iopub.status.idle":"2024-04-28T10:39:36.229894Z","shell.execute_reply.started":"2024-04-28T10:39:36.222636Z","shell.execute_reply":"2024-04-28T10:39:36.228870Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def predict(X_test, model, tokenizer):\n    y_pred = []\n    for text in tqdm(X_test[\"sentences\"]):\n\n        predictions = [[p['entity'], p['word'], p['start'], p['end']] for p in model(text)]\n\n        norm_preds = normalize_preds(predictions)\n        \n        y_pred.append(norm_preds)\n\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:39:36.522084Z","iopub.execute_input":"2024-04-28T10:39:36.522869Z","iopub.status.idle":"2024-04-28T10:39:36.528666Z","shell.execute_reply.started":"2024-04-28T10:39:36.522838Z","shell.execute_reply":"2024-04-28T10:39:36.527688Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom transformers import pipeline\n\nclassifier = pipeline(\"ner\", model=model, tokenizer=tokenizer)\ny_preds = predict(test_data, classifier, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:39:36.858830Z","iopub.execute_input":"2024-04-28T10:39:36.859187Z","iopub.status.idle":"2024-04-28T10:40:13.965453Z","shell.execute_reply.started":"2024-04-28T10:39:36.859157Z","shell.execute_reply":"2024-04-28T10:40:13.964454Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 65/65 [00:36<00:00,  1.78it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data['ners'] = y_preds\ntest_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:40:13.967522Z","iopub.execute_input":"2024-04-28T10:40:13.968317Z","iopub.status.idle":"2024-04-28T10:40:14.006562Z","shell.execute_reply.started":"2024-04-28T10:40:13.968278Z","shell.execute_reply":"2024-04-28T10:40:14.005330Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"    id                                          sentences  \\\n0  584  Владелец «Бирмингема» получил шесть лет тюрьмы...   \n1  585  Акция протеста на Майдане Независимости объявл...   \n2  586  Фольксваген может перейти под контроль Порше \\...   \n\n                                                ners  \n0  [[10, 19, ORGANIZATION], [30, 38, DATE], [30, ...  \n1  [[0, 4, EVENT], [0, 13, EVENT], [18, 38, FACIL...  \n2  [[0, 10, ORGANIZATION], [39, 43, ORGANIZATION]...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentences</th>\n      <th>ners</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>584</td>\n      <td>Владелец «Бирмингема» получил шесть лет тюрьмы...</td>\n      <td>[[10, 19, ORGANIZATION], [30, 38, DATE], [30, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>585</td>\n      <td>Акция протеста на Майдане Независимости объявл...</td>\n      <td>[[0, 4, EVENT], [0, 13, EVENT], [18, 38, FACIL...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>586</td>\n      <td>Фольксваген может перейти под контроль Порше \\...</td>\n      <td>[[0, 10, ORGANIZATION], [39, 43, ORGANIZATION]...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save results to a JSONL file\nsubmission_df = test_data[['id', 'ners']]\nsubmission_df.to_json('test.jsonl', lines=True, orient='records', force_ascii=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:40:14.007951Z","iopub.execute_input":"2024-04-28T10:40:14.008259Z","iopub.status.idle":"2024-04-28T10:40:14.018676Z","shell.execute_reply.started":"2024-04-28T10:40:14.008233Z","shell.execute_reply":"2024-04-28T10:40:14.017747Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import zipfile\nzipfile.ZipFile('test.zip', mode='w').write(\"test.jsonl\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T10:40:14.020668Z","iopub.execute_input":"2024-04-28T10:40:14.021035Z","iopub.status.idle":"2024-04-28T10:40:14.029730Z","shell.execute_reply.started":"2024-04-28T10:40:14.020999Z","shell.execute_reply":"2024-04-28T10:40:14.028839Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}